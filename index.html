<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Integrating Soft Gripper and Gripping Agent for
Universal Robotic Grasping</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Academic Project Page</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Zhuowei Li</a>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Miao Zhang</a><sup>*</sup>,</span>
              <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Shuai Lu</a>,</span>
              <span class="author-block">
                    <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Xueqian Wang</a>,</span>
              <span class="author-block">
                    <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">He Zhang</a></span>      
            </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">University of Nottingham Ningbo China</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Corresponding Author</small></span>
                  </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            It is crucial for successful operation that robots have the ability to flexibly grasp objects and accurately estimate the point of grasp in the field of general-purpose robotic gripping. To address these challenges, we present an Adaptive Rigid-Soft Gripping Agent (GAgent) that combines the adaptability of soft grippers with the cognitive capabilities of Multimodal Language Models (MMLMs) to effectively perform gripping tasks across diverse objects and environments. Our system features a variable-stiffness soft finger that integrates silicone and a Nitinol spring, supported by a rectangular structure and a double-tendon drive mechanism. This design ensures precise and reliable grasping. Additionally, we introduce task-focused prompts and step-level reasoning to fully leverage the generalization and reasoning capabilities of MMLMs. This enables accurate object texture recognition, categorization of objects into multiple hardness levels, and appropriate stiffness modulation to dynamically adjust the gripper's rigidity, ensuring precise grip point estimation. Moreover, our framework includes Data-Driven Gripper features, integrating a vector database and continuous feedback from past experiences to refine grasping strategies over time. Experimental results validate our system's effectiveness in grasping a wide range of objects under varying lighting conditions. These advancements collectively enhance the gripper's adaptability, reliability, and efficiency in handling a broad spectrum of objects, establishing it as a versatile solution for advanced robotic tasks.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Single Image Display -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <!-- Single image container -->
      <figure class="item">
        <img src="gripper.png" alt="MY ALT TEXT" />
        <figcaption>Figure 1: Three-finger hybrid gripper construction including the digital servo, silicone finger, cable-coiling drum, pressure sensor, and embedded spring, designed for precise and responsive motion control.Static analysis of hybrid finger. (a) Schematic diagram of forces on hybrid finger. (b) Diagram of tendon force analysis. The light green in the spring is the tendon. From point B to point A is the flexible section of the spring unit of length and conversely from point A to point B is the rigid section of the spring. The bottom figure analyzes the tendon forces on the finger in bending. T is for tension in the tendon during transmission, N represents the support force of the silicone surface on the spring, f is the friction force，     \theta denotes the bending angle of the flexible unit, \beta is the angle between the friction force and the local coordinates, \varphi is the angle between the front tension and the back tension.</figcaption>
      </figure>
    </div>
  </div>
</section>
<!-- End Single Image Display -->
  
<!-- Single Image Display -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <!-- Single image container -->
      <figure class="item">
        <img src="grip_all1.jpg" alt="MY ALT TEXT" />
        <figcaption>Figure 2: Experimental grasping of objects. Household objects of representative shapes and hardness are selected, which include
round, rectangular, oval, irregular, soft, hard, irregular, and barbed.</figcaption>
      </figure>
    </div>
  </div>
</section>
<!-- End Single Image Display -->


  
<!-- Single Image Display -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <!-- Single image container -->
      <figure class="item">
        <img src="framework.png" alt="MY ALT TEXT" />
        <figcaption>Figure 3: An Adaptive Rigid-Soft Gripping Agent with Vision Language Models, called GAgent. The framework integrates task-focused prompts and step-level reasoning to determine optimal grasping positions. It begins with a task-focused prompt, detailing the role, task description, and tool description. The step-level reasoning involves four steps: Detection, grasping, critical thinking, and reflection. The tool flow section includes a variety of tools for detecting image brightness, adjusting light, segmenting grasped objects, estimating grasp areas, and scoring the stiffness of grasp areas. The postprocess involves determining the final grasping position, calculating the required cable rotation length for precise manipulation, and updating the vector database with the optimal grasping section, position, and stiffness score.</figcaption>
      </figure>
    </div>
  </div>
</section>
<!-- End Single Image Display -->

<!-- Single Image Display -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <!-- Single image container -->
      <figure class="item">
        <img src="case_study.png" alt="MY ALT TEXT" />
        <figcaption>Figure 4: Multi-step process for optimal robotic grasping of various objects.The figure depicts the process of determining optimal grasping points for a three-finger to handle different objects. Each column represents a distinct object, and the text details the stages. The process involves analyzing the object's properties, segmenting the image, identifying and visualizing the optimal grasping section, and determining the specific point of grasp. This systematic approach integrates image processing, object property analysis, and precision in robotic manipulation to achieve optimal grasping for various everyday objects.</figcaption>
      </figure>
    </div>
  </div>
</section>
<!-- End Single Image Display -->

<!-- Four GIFs in a Grid Layout -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <!-- Grid layout for GIFs -->
      <div class="gif-grid" style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 20px;">
        <figure class="item">
          <img src="1.gif" alt="Animation 1" />
          <figcaption>Animation 1: Description of the first animation.</figcaption>
        </figure>
        <figure class="item">
          <img src="2.gif" alt="Animation 2" />
          <figcaption>Animation 2: Description of the second animation.</figcaption>
        </figure>
        <figure class="item">
          <img src="3.gif" alt="Animation 3" />
          <figcaption>Animation 3: Description of the third animation.</figcaption>
        </figure>
        <figure class="item">
          <img src="4.gif" alt="Animation 4" />
          <figcaption>Animation 4: Description of the fourth animation.</figcaption>
        </figure>
      </div>
    </div>
  </div>
</section>
<!-- End Four GIFs in a Grid Layout -->

  

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
